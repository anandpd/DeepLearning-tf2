{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ShakespeareText(NLP).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmLCSCBTu7Xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np, pandas as pd"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhHO23eEvJSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dQijO0fvPAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pathToFile = 'shakespeare.txt'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOxclnVevZCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = open(pathToFile,'r').read()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG_xjlKvvvhI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "72514fd2-5eb4-4457-da90-9dd2de50b261"
      },
      "source": [
        "print(text[:500])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z259HGJNv5yC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = sorted(set(text))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcZpkfWCwD4v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38ea941d-a226-4dda-9062-9cc7ff53615e"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYzPSu7ZwFPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "charToIndex = {char:ind for ind,char in enumerate(vocab)}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkdFxwtswTLY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "77e21eac-8ef1-4c04-c0cb-1a479da3ae5b"
      },
      "source": [
        "charToIndex"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " '(': 6,\n",
              " ')': 7,\n",
              " ',': 8,\n",
              " '-': 9,\n",
              " '.': 10,\n",
              " '0': 11,\n",
              " '1': 12,\n",
              " '2': 13,\n",
              " '3': 14,\n",
              " '4': 15,\n",
              " '5': 16,\n",
              " '6': 17,\n",
              " '7': 18,\n",
              " '8': 19,\n",
              " '9': 20,\n",
              " ':': 21,\n",
              " ';': 22,\n",
              " '<': 23,\n",
              " '>': 24,\n",
              " '?': 25,\n",
              " 'A': 26,\n",
              " 'B': 27,\n",
              " 'C': 28,\n",
              " 'D': 29,\n",
              " 'E': 30,\n",
              " 'F': 31,\n",
              " 'G': 32,\n",
              " 'H': 33,\n",
              " 'I': 34,\n",
              " 'J': 35,\n",
              " 'K': 36,\n",
              " 'L': 37,\n",
              " 'M': 38,\n",
              " 'N': 39,\n",
              " 'O': 40,\n",
              " 'P': 41,\n",
              " 'Q': 42,\n",
              " 'R': 43,\n",
              " 'S': 44,\n",
              " 'T': 45,\n",
              " 'U': 46,\n",
              " 'V': 47,\n",
              " 'W': 48,\n",
              " 'X': 49,\n",
              " 'Y': 50,\n",
              " 'Z': 51,\n",
              " '[': 52,\n",
              " ']': 53,\n",
              " '_': 54,\n",
              " '`': 55,\n",
              " 'a': 56,\n",
              " 'b': 57,\n",
              " 'c': 58,\n",
              " 'd': 59,\n",
              " 'e': 60,\n",
              " 'f': 61,\n",
              " 'g': 62,\n",
              " 'h': 63,\n",
              " 'i': 64,\n",
              " 'j': 65,\n",
              " 'k': 66,\n",
              " 'l': 67,\n",
              " 'm': 68,\n",
              " 'n': 69,\n",
              " 'o': 70,\n",
              " 'p': 71,\n",
              " 'q': 72,\n",
              " 'r': 73,\n",
              " 's': 74,\n",
              " 't': 75,\n",
              " 'u': 76,\n",
              " 'v': 77,\n",
              " 'w': 78,\n",
              " 'x': 79,\n",
              " 'y': 80,\n",
              " 'z': 81,\n",
              " '|': 82,\n",
              " '}': 83}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgi8M0PjwUmX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba324e60-da48-423a-a978-6d1bf3b321f1"
      },
      "source": [
        "charToIndex['H']"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uCIUHpFwX8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indexToChar = np.array(vocab)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgSUbgmhwa1S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b5c7bd64-093b-42cf-b366-c24b377bb85b"
      },
      "source": [
        "indexToChar[33]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'H'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCt6TLZAwcpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encodedText = np.array([charToIndex[c] for c in text])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxD7qmrFwns5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3d5ef78-865a-4642-ffa7-58196ed4e00a"
      },
      "source": [
        "encodedText"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  1, ..., 30, 39, 29])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVoPMljvwpH5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47a20b39-dfee-4f81-afa0-df32a5aadf06"
      },
      "source": [
        "encodedText.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5445609,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djs4mQ3Pwsmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = text[500:1000]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxegdjwQwztc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "f7892fa4-a5ab-4d04-9dfc-00979c98ef84"
      },
      "source": [
        "print(sample)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "d buriest thy content,\n",
            "  And tender churl mak'st waste in niggarding:\n",
            "    Pity the world, or else this glutton be,\n",
            "    To eat the world's due, by the grave and thee.\n",
            "\n",
            "\n",
            "                     2\n",
            "  When forty winters shall besiege thy brow,\n",
            "  And dig deep trenches in thy beauty's field,\n",
            "  Thy youth's proud livery so gazed on now,\n",
            "  Will be a tattered weed of small worth held:  \n",
            "  Then being asked, where all thy beauty lies,\n",
            "  Where all the treasure of thy lusty days;\n",
            "  To say within thine own deep su\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLw9PV46w0rj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "a430c556-834c-4acc-f906-88b87296093c"
      },
      "source": [
        "encodedText[500:1000]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([59,  1, 57, 76, 73, 64, 60, 74, 75,  1, 75, 63, 80,  1, 58, 70, 69,\n",
              "       75, 60, 69, 75,  8,  0,  1,  1, 26, 69, 59,  1, 75, 60, 69, 59, 60,\n",
              "       73,  1, 58, 63, 76, 73, 67,  1, 68, 56, 66,  5, 74, 75,  1, 78, 56,\n",
              "       74, 75, 60,  1, 64, 69,  1, 69, 64, 62, 62, 56, 73, 59, 64, 69, 62,\n",
              "       21,  0,  1,  1,  1,  1, 41, 64, 75, 80,  1, 75, 63, 60,  1, 78, 70,\n",
              "       73, 67, 59,  8,  1, 70, 73,  1, 60, 67, 74, 60,  1, 75, 63, 64, 74,\n",
              "        1, 62, 67, 76, 75, 75, 70, 69,  1, 57, 60,  8,  0,  1,  1,  1,  1,\n",
              "       45, 70,  1, 60, 56, 75,  1, 75, 63, 60,  1, 78, 70, 73, 67, 59,  5,\n",
              "       74,  1, 59, 76, 60,  8,  1, 57, 80,  1, 75, 63, 60,  1, 62, 73, 56,\n",
              "       77, 60,  1, 56, 69, 59,  1, 75, 63, 60, 60, 10,  0,  0,  0,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1, 13,  0,  1,  1, 48, 63, 60, 69,  1, 61, 70, 73, 75, 80,  1,\n",
              "       78, 64, 69, 75, 60, 73, 74,  1, 74, 63, 56, 67, 67,  1, 57, 60, 74,\n",
              "       64, 60, 62, 60,  1, 75, 63, 80,  1, 57, 73, 70, 78,  8,  0,  1,  1,\n",
              "       26, 69, 59,  1, 59, 64, 62,  1, 59, 60, 60, 71,  1, 75, 73, 60, 69,\n",
              "       58, 63, 60, 74,  1, 64, 69,  1, 75, 63, 80,  1, 57, 60, 56, 76, 75,\n",
              "       80,  5, 74,  1, 61, 64, 60, 67, 59,  8,  0,  1,  1, 45, 63, 80,  1,\n",
              "       80, 70, 76, 75, 63,  5, 74,  1, 71, 73, 70, 76, 59,  1, 67, 64, 77,\n",
              "       60, 73, 80,  1, 74, 70,  1, 62, 56, 81, 60, 59,  1, 70, 69,  1, 69,\n",
              "       70, 78,  8,  0,  1,  1, 48, 64, 67, 67,  1, 57, 60,  1, 56,  1, 75,\n",
              "       56, 75, 75, 60, 73, 60, 59,  1, 78, 60, 60, 59,  1, 70, 61,  1, 74,\n",
              "       68, 56, 67, 67,  1, 78, 70, 73, 75, 63,  1, 63, 60, 67, 59, 21,  1,\n",
              "        1,  0,  1,  1, 45, 63, 60, 69,  1, 57, 60, 64, 69, 62,  1, 56, 74,\n",
              "       66, 60, 59,  8,  1, 78, 63, 60, 73, 60,  1, 56, 67, 67,  1, 75, 63,\n",
              "       80,  1, 57, 60, 56, 76, 75, 80,  1, 67, 64, 60, 74,  8,  0,  1,  1,\n",
              "       48, 63, 60, 73, 60,  1, 56, 67, 67,  1, 75, 63, 60,  1, 75, 73, 60,\n",
              "       56, 74, 76, 73, 60,  1, 70, 61,  1, 75, 63, 80,  1, 67, 76, 74, 75,\n",
              "       80,  1, 59, 56, 80, 74, 22,  0,  1,  1, 45, 70,  1, 74, 56, 80,  1,\n",
              "       78, 64, 75, 63, 64, 69,  1, 75, 63, 64, 69, 60,  1, 70, 78, 69,  1,\n",
              "       59, 60, 60, 71,  1, 74, 76])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YkEx9yrxmIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequenceLength = 120\n",
        "totalSequence = len(text) // (sequenceLength+1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75nBRwvdx_4V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f6dc4f2-84c2-4654-edb8-d1bba57470ab"
      },
      "source": [
        "totalSequence"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DYPV8JzyBZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "charDataset = tf.data.Dataset.from_tensor_slices(encodedText)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy00-FXJyMfQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0b172fb-8f60-45b0-b75a-68310e020d51"
      },
      "source": [
        "type(charDataset)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkSB_EGwyRpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = charDataset.batch(sequenceLength+1, drop_remainder=True)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk2I9Sw8ynII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createSequenceTarget(seq):\n",
        "  input_text = seq[:-1]\n",
        "  target_text = seq[1:]\n",
        "  return input_text,target_text"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPu1O2VwzIHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = sequences.map(createSequenceTarget)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywrYVTom0EF5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "797ee131-0442-4330-c9ee-d728af3304bd"
      },
      "source": [
        "# 1st batch : \n",
        "for inputText,targetText in dataset.take(1):\n",
        "    print(inputText.numpy())\n",
        "    print(\"\".join(indexToChar[inputText.numpy()]))\n",
        "    print(\"\\n\")\n",
        "    print(targetText.numpy())\n",
        "    print(\"\".join(indexToChar[targetText.numpy()]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
            "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
            "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
            " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
            " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But\n",
            "\n",
            "\n",
            "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
            "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
            " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
            " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
            "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWW3Os5y0g5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batchSize = 128"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOAKQApE15bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bufferSize = 10000\n",
        "dataset = dataset.shuffle(bufferSize).batch(batchSize,drop_remainder=True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0tFbIcw2TLx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6dbc8136-1c16-40c3-f509-c9971fad7695"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((128, 120), (128, 120)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r934fW-BkIYc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2df4bd4a-19ee-46a3-eb27-997ed5828e1f"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1lQZoQs2UuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabSize = len(vocab)\n",
        "embedDims = 64\n",
        "rnnNeurons = 1026"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDlP6CGF2qM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzXTSerx2vVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sparseCatLoss(y_true, y_pred):\n",
        "  return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diCVx9003Ayk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ozVOQWN3VYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Embedding,GRU,Dense"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbXfbHgY3clf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createModel(_vocabSize, _embedDims, _rnnNeurons, _batchSize):\n",
        "  model = Sequential([\n",
        "          Embedding(_vocabSize, _embedDims, batch_input_shape = [_batchSize,None]),\n",
        "          GRU(_rnnNeurons,return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
        "          Dense(_vocabSize)\n",
        "  ])\n",
        "  model.compile('adam', loss = sparse_categorical_crossentropy)\n",
        "  return model"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-MggsQX4SEv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " model = createModel ( _vocabSize = vocabSize,\n",
        "                       _embedDims = embedDims,\n",
        "                       _rnnNeurons = rnnNeurons,\n",
        "                       _batchSize = batchSize)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGDHSTR84aN7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "e04b07f8-2780-488a-bc29-509667ed69e4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (128, None, 64)           5376      \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (128, None, 1026)         3361176   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (128, None, 84)           86268     \n",
            "=================================================================\n",
            "Total params: 3,452,820\n",
            "Trainable params: 3,452,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUdrSaU94b3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for inputExampleBatch,targetExampleBatch in dataset.take(1):\n",
        "  exampleBatchPredictions = model(inputExampleBatch)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1wNBhKJ42UF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "d129365e-20af-43d4-9888-d58f55f1f33b"
      },
      "source": [
        "exampleBatchPredictions[0]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(120, 84), dtype=float32, numpy=\n",
              "array([[-0.00405877, -0.0031926 ,  0.00437547, ...,  0.00382049,\n",
              "         0.00147452,  0.00215603],\n",
              "       [-0.00063046, -0.00200269, -0.00774149, ...,  0.00752806,\n",
              "         0.00308234,  0.00017884],\n",
              "       [ 0.00206812,  0.00154192,  0.00159745, ...,  0.00374575,\n",
              "         0.00333671,  0.00506078],\n",
              "       ...,\n",
              "       [ 0.00394621, -0.0051925 , -0.00805531, ...,  0.00716522,\n",
              "        -0.00382652,  0.01063507],\n",
              "       [ 0.00228172, -0.00146451,  0.00037656, ...,  0.00021519,\n",
              "        -0.00010536,  0.00184603],\n",
              "       [ 0.00329038,  0.00037758,  0.00341793, ..., -0.00281705,\n",
              "         0.00124753, -0.00275264]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6qdHWUa5ANU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampleIndices = tf.random.categorical(exampleBatchPredictions[0], num_samples=1)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVm_OL9E5V2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampleIndices = tf.squeeze(sampleIndices, axis=-1).numpy()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F9vyBL25W0i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "ecb6bfe7-5371-430b-fc82-0590913fb8d6"
      },
      "source": [
        "indexToChar[sampleIndices]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['\\n', 'b', 'B', 'q', 'R', ' ', 'O', 'k', '0', '3', 'c', 'T', 'n',\n",
              "       'r', 'L', '3', '!', 'O', 'V', 'N', '`', 'E', 'o', 'k', 'M', 'h',\n",
              "       ' ', 'U', 'L', 'b', 'w', 'e', 'l', 'd', 'i', 'S', 'g', 'N', 't',\n",
              "       '!', '!', '3', 'D', \"'\", 'B', 'a', 'A', 'a', '\"', 'G', '<', 'z',\n",
              "       'y', 'A', '(', 'n', '5', 'y', 'j', '1', ',', 'r', 'l', 'b', 'e',\n",
              "       ';', 'f', 'P', 'x', 'l', 'H', 'a', '-', 't', '1', 'i', 't', 'o',\n",
              "       '1', 'p', 'Q', 'L', 'P', '\"', '.', 'b', '\"', 'm', 'a', '>', '<',\n",
              "       '>', 'Y', 'k', '_', 'P', 'n', '?', '[', 'z', '6', ':', '9', 'S',\n",
              "       'J', ';', '0', 'k', 'Q', 'W', '`', 'Q', 'w', 'z', ',', 'I', 'N',\n",
              "       'R', '7', 'F'], dtype='<U1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH74veIw5s3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 30"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qntPpbVC5zBm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bfbdcc70-d898-4aa4-fcb6-b76ba2cc5011"
      },
      "source": [
        "model.fit(dataset, epochs = epochs)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "351/351 [==============================] - 92s 261ms/step - loss: 2.9564\n",
            "Epoch 2/30\n",
            "351/351 [==============================] - 91s 260ms/step - loss: 2.6725\n",
            "Epoch 3/30\n",
            "351/351 [==============================] - 91s 261ms/step - loss: 2.6058\n",
            "Epoch 4/30\n",
            "351/351 [==============================] - 91s 260ms/step - loss: 2.6553\n",
            "Epoch 5/30\n",
            "351/351 [==============================] - 91s 259ms/step - loss: 2.6121\n",
            "Epoch 6/30\n",
            "351/351 [==============================] - 92s 261ms/step - loss: 2.5465\n",
            "Epoch 7/30\n",
            "351/351 [==============================] - 91s 260ms/step - loss: 2.5274\n",
            "Epoch 8/30\n",
            "351/351 [==============================] - 91s 261ms/step - loss: 2.8277\n",
            "Epoch 9/30\n",
            "351/351 [==============================] - 92s 262ms/step - loss: 2.7663\n",
            "Epoch 10/30\n",
            "351/351 [==============================] - 92s 262ms/step - loss: 2.7647\n",
            "Epoch 11/30\n",
            "351/351 [==============================] - 92s 261ms/step - loss: 2.6453\n",
            "Epoch 12/30\n",
            "351/351 [==============================] - 92s 262ms/step - loss: 2.6418\n",
            "Epoch 13/30\n",
            "351/351 [==============================] - 91s 260ms/step - loss: 2.7346\n",
            "Epoch 14/30\n",
            "351/351 [==============================] - 92s 261ms/step - loss: 2.6957\n",
            "Epoch 15/30\n",
            "351/351 [==============================] - 92s 262ms/step - loss: 2.8048\n",
            "Epoch 16/30\n",
            "351/351 [==============================] - 92s 263ms/step - loss: 2.9055\n",
            "Epoch 17/30\n",
            "351/351 [==============================] - 92s 263ms/step - loss: 2.8720\n",
            "Epoch 18/30\n",
            "351/351 [==============================] - 92s 262ms/step - loss: 2.8507\n",
            "Epoch 19/30\n",
            "351/351 [==============================] - 92s 262ms/step - loss: 2.9001\n",
            "Epoch 20/30\n",
            "351/351 [==============================] - 92s 263ms/step - loss: 2.8545\n",
            "Epoch 21/30\n",
            "351/351 [==============================] - 92s 261ms/step - loss: 2.9374\n",
            "Epoch 22/30\n",
            "351/351 [==============================] - 92s 263ms/step - loss: 2.9602\n",
            "Epoch 23/30\n",
            "351/351 [==============================] - 92s 263ms/step - loss: 2.9225\n",
            "Epoch 24/30\n",
            "351/351 [==============================] - 92s 262ms/step - loss: 2.9297\n",
            "Epoch 25/30\n",
            "351/351 [==============================] - 92s 263ms/step - loss: 2.8785\n",
            "Epoch 26/30\n",
            "351/351 [==============================] - 92s 262ms/step - loss: 2.9968\n",
            "Epoch 27/30\n",
            "351/351 [==============================] - 92s 262ms/step - loss: 2.9937\n",
            "Epoch 28/30\n",
            "351/351 [==============================] - 92s 262ms/step - loss: 2.9475\n",
            "Epoch 29/30\n",
            "351/351 [==============================] - 92s 262ms/step - loss: 2.8761\n",
            "Epoch 30/30\n",
            "351/351 [==============================] - 92s 263ms/step - loss: 3.0431\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1180808ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7AmIuG655uY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1_hpBwNEggL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('shakespeare_gen.h5')"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jwMo-hKElXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = createModel(_vocabSize=vocabSize,\n",
        "                    _embedDims=embedDims,\n",
        "                    _rnnNeurons=rnnNeurons,\n",
        "                    _batchSize=1)\n",
        "model.load_weights('shakespeare_gen.h5')\n",
        "model.build(tf.TensorShape([1,None]))"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myUMZMD8FEz7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "d46626ba-1c80-4117-9fdb-cfa80e51b87a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (1, None, 64)             5376      \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (1, None, 1026)           3361176   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (1, None, 84)             86268     \n",
            "=================================================================\n",
            "Total params: 3,452,820\n",
            "Trainable params: 3,452,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7nQXBLgFQ6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generateText(_model, _startSeed, _genSize=500, _temp=1.0):\n",
        "  num_to_generate = _genSize\n",
        "  input_eval = [charToIndex[s] for s in _startSeed]\n",
        "  input_eval = tf.expand_dims(input_eval,0)\n",
        "  generatedText = []\n",
        "  temperature = _temp\n",
        "  _model.reset_states()\n",
        "  \n",
        "  for i in range(num_to_generate):\n",
        "    predictions = _model(input_eval)\n",
        "    predictions = tf.squeeze(predictions,0)\n",
        "    predictions = predictions/temperature\n",
        "    predicted_index = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "    input_eval = tf.expand_dims([predicted_index],0)\n",
        "    generatedText.append(indexToChar[predicted_index])\n",
        "  return (_startSeed+ \"\".join(generatedText))"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HInghASVKMx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "4d254b4e-748c-4131-b8a4-4cb65d43fa2d"
      },
      "source": [
        "print(generateText(_model=model,_startSeed=\"JULIET\", _genSize=1000))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "JULIETES] What, what? in cords, forsworn; lords, good win,\n",
            "    You have shak'd first seen when he will be,\n",
            "    And then I'll make thee friendly with the foot,\n",
            "    As will return, and hear me speak it for your\n",
            "    own, the very jests will greet away me good its with beats my fleer\n",
            "    The ruin of the world, or gracious mirth,\n",
            "    Hearing thee harmen's at ours that should be ready.\n",
            "  PUBLIUS. All dispossesses, pronation;\n",
            "    Bloody, shall quickly took upon her,\n",
            "    here, by their other sumage is bear.                        SCARUS. Let us wreck down, and creep into the coward,\n",
            "    As true in love, so fit my brother would\n",
            "    With wit of your companion!  \n",
            "  THERSITES. No, true, to save him with such mighty honesty than he:\n",
            "    'Will't was committed?\n",
            "  BEROWNE. I cannot tell; thou sects and honourable\n",
            "    or anying soul upon him; no, I will; and so the gentleman of this head\n",
            "    Stood in this brown friend, and what 'Welliurd name, a rabble came.\n",
            "  VOLUMNILUS. 'Tis so;  peace, but be avoided\n",
            "    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGAS7cs1-e7m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4e5d4291-9995-4aad-d542-e4fcefc6eabb"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"shakespeare_gen.h5\")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_01599927-efa8-4431-a647-4f9d80727037\", \"shakespeare_gen.h5\", 41465856)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVoTKMF3-p1e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}